{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cad129c2-53fd-4440-b979-5d78ad882604",
   "metadata": {},
   "source": [
    "The reference for this notebook is the dspy documentation [here](https://dspy-docs.vercel.app/docs/tutorials/simplified-baleen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5988ad35-c31b-4a50-b98e-3fceaa2b4cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd40a85-4dec-46e6-9fbd-f6eaa90a6d5d",
   "metadata": {},
   "source": [
    "## Configuring LM and RM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c3c1c2-3ebb-4748-9f6b-8ae69bc2c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_model = dspy.OllamaLocal(model=\"llama3\",model_type='text',\n",
    "                                max_tokens=350,\n",
    "                                temperature=0.1,\n",
    "                                top_p=0.8, frequency_penalty=1.17, top_k=40)\n",
    "\n",
    "colbertv2_wiki17_abstracts = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')\n",
    "\n",
    "dspy.settings.configure(lm=ollama_model, rm=colbertv2_wiki17_abstracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5180a099-144f-4a1e-bebc-36d893b43a63",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c93ee9-3a6b-4a7c-9bdf-f12e7e39eeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.datasets import HotPotQA\n",
    "\n",
    "# Load the dataset.\n",
    "dataset = HotPotQA(train_seed=1, train_size=20, eval_seed=2023, dev_size=50, test_size=0)\n",
    "\n",
    "# Tell DSPy that the 'question' field is the input. Any other fields are labels and/or metadata.\n",
    "trainset = [x.with_inputs('question') for x in dataset.train]\n",
    "devset = [x.with_inputs('question') for x in dataset.dev]\n",
    "\n",
    "len(trainset), len(devset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224f56ff-2c6d-4157-8e39-9c2265371dc1",
   "metadata": {},
   "source": [
    "## Building Signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61ed189-e376-4c8a-9324-dfec0e34000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd132c7a-0aab-414e-8b4e-590f5d067e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateSearchQuery(dspy.Signature):\n",
    "    \"\"\"Write a simple search query that will help answer a complex question.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    query = dspy.OutputField()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc19a7cb-ab48-45e5-9122-29acce78d724",
   "metadata": {},
   "source": [
    "## Building the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e896bc55-60ff-45e3-8cee-172bcbe52b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsp.utils import deduplicate\n",
    "\n",
    "class SimplifiedBaleen(dspy.Module):\n",
    "    def __init__(self, passages_per_hop=3, max_hops=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.generate_query = [dspy.ChainOfThought(GenerateSearchQuery) for _ in range(max_hops)]\n",
    "        self.retrieve = dspy.Retrieve(k=passages_per_hop)\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "        self.max_hops = max_hops\n",
    "    \n",
    "    def forward(self, question):\n",
    "        context = []\n",
    "        \n",
    "        for hop in range(self.max_hops):\n",
    "            query = self.generate_query[hop](context=context, question=question).query\n",
    "            passages = self.retrieve(query).passages\n",
    "            context = deduplicate(context + passages)\n",
    "\n",
    "        pred = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=pred.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b35d1c-e5a0-4098-95b7-5b385275e48e",
   "metadata": {},
   "source": [
    "## Executing the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290be6a0-6a6a-4f3c-98bd-311f986d9dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask any question you like to this simple RAG program.\n",
    "my_question = \"How many storeys are in the castle that David Gregory inherited?\"\n",
    "\n",
    "# Get the prediction. This contains `pred.context` and `pred.answer`.\n",
    "uncompiled_baleen = SimplifiedBaleen()  # uncompiled (i.e., zero-shot) program\n",
    "pred = uncompiled_baleen(my_question)\n",
    "\n",
    "# Print the contexts and the answer.\n",
    "print(f\"Question: {my_question}\")\n",
    "print(f\"Predicted Answer: {pred.answer}\")\n",
    "print(f\"Retrieved Contexts (truncated): {[c[:200] + '...' for c in pred.context]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0b5d07-9cbb-495e-acc2-c54d8316efd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_model.inspect_history(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4286618f-a3bd-4715-a841-1ce2227abfb9",
   "metadata": {},
   "source": [
    "## Optimizing the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17af8180-ca71-49a0-a088-a9fb97b536fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_context_and_answer_and_hops(example, pred, trace=None):\n",
    "    if not dspy.evaluate.answer_exact_match(example, pred): return False\n",
    "    if not dspy.evaluate.answer_passage_match(example, pred): return False\n",
    "\n",
    "    hops = [example.question] + [outputs.query for *_, outputs in trace if 'query' in outputs]\n",
    "\n",
    "    if max([len(h) for h in hops]) > 100: return False\n",
    "    if any(dspy.evaluate.answer_exact_match_str(hops[idx], hops[:idx], frac=0.8) for idx in range(2, len(hops))): return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cc79e8-0d13-42d9-b3fc-b337e8e67b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "teleprompter = BootstrapFewShot(metric=validate_context_and_answer_and_hops)\n",
    "compiled_baleen = teleprompter.compile(SimplifiedBaleen(), teacher=SimplifiedBaleen(passages_per_hop=2), trainset=trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65279cf7-9d32-4432-a0fb-cf24c9fdbbc7",
   "metadata": {},
   "source": [
    "## Evaluating the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c2ec28-95fe-4e81-ae71-6a66475c66fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.evaluate.evaluate import Evaluate\n",
    "\n",
    "# Define metric to check if we retrieved the correct documents\n",
    "def gold_passages_retrieved(example, pred, trace=None):\n",
    "    gold_titles = set(map(dspy.evaluate.normalize_text, example[\"gold_titles\"]))\n",
    "    found_titles = set(\n",
    "        map(dspy.evaluate.normalize_text, [c.split(\" | \")[0] for c in pred.context])\n",
    "    )\n",
    "    return gold_titles.issubset(found_titles)\n",
    "\n",
    "# Set up the `evaluate_on_hotpotqa` function. We'll use this many times below.\n",
    "evaluate_on_hotpotqa = Evaluate(devset=devset, num_threads=1, display_progress=True, display_table=5)\n",
    "\n",
    "uncompiled_baleen_retrieval_score = evaluate_on_hotpotqa(uncompiled_baleen, metric=gold_passages_retrieved, display=False)\n",
    "\n",
    "compiled_baleen_retrieval_score = evaluate_on_hotpotqa(compiled_baleen, metric=gold_passages_retrieved)\n",
    "\n",
    "print(f\"## Retrieval Score for uncompiled Baleen: {uncompiled_baleen_retrieval_score}\")\n",
    "print(f\"## Retrieval Score for compiled Baleen: {compiled_baleen_retrieval_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
